# kafka

## 高吞吐量

kafka 设计用于支持高吞吐量的数据传输，能够处理每秒百万级别的消息，适用于大规模数据的实时处理场景


## 持久化存储

kafka将消息持久化到磁盘，并通过复制机制来提高容错能力。这意味着即使消费者离线，也可以重新上线后消费之前未处理的消息

## 分布式架构
Kafka 本身是分布式的，支持集群部署。它使用分区（partitions）和副本（replicas）机制来实现负载均衡和高可用性。

## 消息顺序保证

在每个分区内部，kafka能够保证消息的顺序性，这对于某些需要严格顺序处理的应用场景非常重要。


## 发布/订阅
Kafka 支持传统的发布/订阅模式，允许一个或多个消费者订阅主题（topics），并根据需求消费消息。

## 灵活的消息传递保障

At most once：消息可能丢失但不会重复。
At least once：确保所有消息都被处理，但可能存在重复。
Exactly once：确保消息既不丢失也不重复，这是最严格的保证方式，但在性能上可能会有所牺牲。


## 可扩展性

通过增加更多的代理（brokers）和分区，Kafka 可以轻松地横向扩展，以适应不断增长的数据量和吞吐量需求。

## 流处理支持

除了作为消息队列外，kafka还提供了流处理能力，使得用户可以直接在kafka上面进行复杂的数据传输和分析操作

## 安全性

Kafka 提供了多种安全措施，包括 SSL/TLS 加密、SASL 认证等，确保数据的安全传输和访问控制。


1. 高吞吐量测试
工具：可以使用 kafka-producer-perf-test.sh 和 kafka-consumer-perf-test.sh 脚本进行性能测试。
步骤：
使用生产者性能测试脚本向特定主题发送大量消息，调整参数如**消息大小**、**批次大小**、**压缩类型**等，观察吞吐量的变化。
使用消费者性能测试脚本来读取消息，并监测消费速率。
2. 持久化存储与复制测试
工具：Kafka 自带的命令行工具或第三方监控工具如 Prometheus + Grafana。
步骤：
创建一个具有多个副本的主题，然后手动关闭主副本所在的 broker，检查消费者是否能无缝切换到从副本继续消费。
使用命令行工具或监控工具查看日志段文件（log segments）以及它们的复制状态。
3. 消息顺序保证测试
工具：自定义简单的生产者和消费者程序。
步骤：
生产者按照特定顺序发送一系列带有顺序编号的消息到单一分区的主题中。
消费者订阅该主题并记录接收到的消息顺序，对比原始发送顺序以验证顺序一致性。
4. 发布/订阅模式测试
工具：Kafka 客户端库（如 Java、Python 等）编写简单应用程序。
步骤：
创建一个主题并配置多个消费者组订阅该主题。
生产者发送消息至该主题，每个消费者组应独立接收所有消息，而同一组内的消费者共享消息负载。
5. 消息传递保障测试
工具：编写测试程序模拟不同的消息传递场景。
步骤：
配置生产者和消费者以不同的消息传递保障级别运行（至少一次、最多一次、精确一次），并通过手动引入网络延迟或故障来观察消息传递的行为。
6. 可扩展性测试
工具：通过增加分区数或添加更多 brokers 来模拟扩展。
步骤：
增加主题的分区数量，观察生产和消费速率的变化。
向集群添加新的 brokers 并重新分配分区，确保系统能够平稳地处理更多的流量。
7. 流处理支持测试
工具：Kafka Streams 或 KSQL。
步骤：
使用 Kafka Streams API 编写流处理应用，执行基本的操作如过滤、聚合等。
利用 KSQL 进行更复杂的实时数据处理任务，并验证结果的正确性。
8. 安全性测试
工具：启用 SSL/TLS 和 SASL 认证机制。
步骤：
配置 Kafka 集群使用 SSL 加密通信，并通过客户端连接测试加密的有效性。
设置 SASL 认证，确保只有授权用户才能访问集群资源。