# 数据仓库

数据测试 ，SQL能力，用例执行全面性，数仓


## 数据准确性
源与目标对比：验证从源系统抽离的数据是否正确无误的加载到了数据仓库中
ETL逻辑验证：检查ETL流程中的转换逻辑是否正确应用，包括了数据清洗、转换规则等

## 数据完整性测试
主键/外键约束：确认所有必要的主键和外键关系已经建立，保证数据的引用完整性
维度表和事实表的一致性：确保维度表和事实表之间的连接是正确的，并且没有丢失任何数据

## 性能测试
查询响应时间：评估在不同的负载下，关键业务查询的查询时间和响应速度
并发用户测试：模拟多个用户同时访问系统的情况，测试系统的稳定性和响应能力

## 数据质量测试
空值和默认值检查：确保不允许为空的字段不包含空值，以及使用了适当的默认值

重复记录检测：查找并处理数据仓库中的重复记录

## 安全性和权限测试
访问权限：验证只有授权用户才能访问特定的数据集
设计跟踪：确保所有的数据库操作都可以被追踪到具体的用户和时间点

## 用户接受度测试
业务场景模拟：通过实际业务案例来验证数据仓库是否满足最终用户的业务需求
反馈收集：从最终用户那里收集关于数据展示，报告功能等方面的反馈

## 回归测试
变更影响分析：当对数据仓库进行更新或者修改时，需要进行回归测试以确保这些更改不会破坏现有的功能




# kafka

## 数据质量

Schema注册与验证：使用如Confluent Schema Registry这样的工具为你的消息定义schema，并在生产者端进行验证，以确保发送的数据符合预期格式。
数据清洗：在将数据发送到Kafka之前，通过数据清洗步骤去除不完整或错误的数据。
单元测试：编写单元测试用例来验证生产者发送的消息是否符合预期。


## 数据准确性

### 幂等性生产者

启用kafka的幂等性特性，可以避免重复消息的问题，从而提高数据准确性


### 事务支持
利用kafka的事务功能，确保一组消息要么全部成功提交，要么全部失败回滚，这对于需要高一致性的应用场景特别有用


### 消费者验证

在消费者端实现逻辑来验证收到的数据是否正确无误


## 数据有序性

### 分区键
为了保持特定类型消息的顺序，可以通过设置相同的分区键使得相关消息被路由到同一个分区中。因为在同一个分区内，消息是严格按照它们到达顺序存储和消费的


### 单线程处理

确保只有一个消费者实例处理某个主题的特定分区，这样可以保证消息被顺序处理。不过，这可能影响吞吐量


### 时间戳同步

对于某些应用来说，可能还需要考虑使用消息的时间戳来进一步保障顺序性，特别是在消息重放场景下